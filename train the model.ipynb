{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Test trained model.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "1_nEy51hGPsb",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1e54bf83-ad5c-4e5a-c4a8-eb9b1e67a003"
   },
   "source": [
    "#@title Select the task type you want to try out, then run this cell\n",
    "\n",
    "#@markdown The model we are going to use is a multitask model. That means that \n",
    "#@markdown it can make predictions on 3 different tasks!\n",
    "\n",
    "#@markdown First, select the task type you would like to try. \n",
    "task_type = \"product\" #@param [\"product\",\"reactants\",\"reagents\"] {type:\"string\"}\n",
    "task2prefix = {\n",
    "    'product': \"Product:\",\n",
    "    'reactants': \"Reactants:\",\n",
    "    'reagents': \"Reagents:\",\n",
    "}\n",
    "#@markdown Then, fill your input sequence in:\n",
    "\n",
    "#@markdown You can find example [here](https://gist.github.com/HelloJocelynLu/7f10386e1678c4335914aaac37113c78):\n",
    "\n",
    "input_seq = \"CN1CCNCC1.OCCCBr.Cc1ccccc1>>\" #@param {type:\"string\"}\n",
    "import sys\n",
    "# sys.path.append('/usr/local/lib/python3.7/site-packages/')\n",
    "from rdkit import Chem\n",
    "\n",
    "if task_type == \"product\":\n",
    "  mols = input_seq.split('>')\n",
    "  if len(mols) != 3:\n",
    "    raise ValueError(\"Make sure you provided reactants and reagents with two '>'s\")\n",
    "  else:\n",
    "    for mol in mols:\n",
    "      # Only Check non-blank string\n",
    "      if mol and not Chem.MolFromSmiles(mol):\n",
    "        raise ValueError(f\"Molecule smiles {mol} is invalid!\")\n",
    "elif task_type == \"reactants\":\n",
    "  if not Chem.MolFromSmiles(input_seq):\n",
    "    raise ValueError(f\"Molecule smiles {input_seq} is invalid!\")\n",
    "else:\n",
    "  mols = input_seq.split('>>')\n",
    "  for mol in mols:\n",
    "    if not mol or not Chem.MolFromSmiles(mol):\n",
    "       raise ValueError(f\"Molecule smiles {mol} is invalid! Make sure you have include two '>'s\")\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ### Advanced settings\n",
    "#@markdown What the beam size we should use in prediction?\n",
    "beam_size = \"10\" #@param [\"1\", \"3\", \"5\", \"10\"]\n",
    "beam_size = int(beam_size)\n",
    "#@markdown The number of sequences to return\n",
    "num_seq = \"5\" #@param [\"1\", \"3\", \"5\", \"10\"]\n",
    "num_seq = int(num_seq)\n",
    "\n",
    "if num_seq > beam_size:\n",
    "  raise ValueError(\"num_seq should be smaller than beam_size!\")\n",
    "\n",
    "input_seq = task2prefix[task_type]+input_seq\n",
    "model_path = \"model/\"\n",
    "print(\"You are good to go!\")"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are good to go!\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CN1CCNCC1.OCCCBr.Cc1ccccc1', '', '']\n",
      "Product:CN1CCNCC1.OCCCBr.Cc1ccccc1>>\n"
     ]
    }
   ],
   "source": [
    "print(mols)\n",
    "print(input_seq)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3_QfyFKdav8v",
    "outputId": "94587a13-3fd5-4d92-b6ae-a1b7c4a106c3"
   },
   "source": [
    "#@title Make predictions\n",
    "from transformers import T5ForConditionalGeneration\n",
    "from t5chem import SimpleTokenizer\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_path)\n",
    "tokenizer = SimpleTokenizer(vocab_file='model/vocab.pt')\n",
    "inputs = tokenizer.encode(input_seq, return_tensors='pt')\n",
    "outputs = model.generate(input_ids=inputs, max_length=300, early_stopping=True, num_beams=beam_size, num_return_sequences=num_seq)\n",
    "print(\"Model input:\", input_seq)\n",
    "for i, pred in enumerate(outputs):\n",
    "  print(\"Prediction\", str(i+1)+\":\", tokenizer.decode(pred, skip_special_tokens=True))"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model input: Product:CN1CCNCC1.OCCCBr.Cc1ccccc1>>\n",
      "Prediction 1: CC1CCCC2(C)c3ccccc3C(=O)N12\n",
      "Prediction 2: CC1(C)C(=O)N(C2CCCCC2)c2ccccc21\n",
      "Prediction 3: CC1CCCC2(C)c3ccccc3C(=O)N2C1\n",
      "Prediction 4: CC1(C)CCCC(C)(C)N1OCCCC1\n",
      "Prediction 5: CCOC(=O)C1(C(=O)OCC)C(c2ccccc2)C2ccccc21\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[85,  5, 13,  9,  5,  5, 13,  5,  5,  9, 27, 10,  5,  5,  5, 28, 30, 27,\n          5,  6,  9,  6,  6,  6,  6,  6,  9, 37, 37]])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UGUBLzB3C6WN"
   },
   "source": [
    "# Instructions <a name=\"Instructions\"></a>\n",
    "**Quick start**\n",
    "1. Select a task type to test\n",
    "2. Input a sequence to test on\n",
    "3. (Optionally) Select the number of returned predictions\n",
    "4. Run all\n",
    "\n",
    "**Bugs**\n",
    "- If you encounter any bugs, please report the issue to https://github.com/HelloJocelynLu/t5chem/issues\n"
   ]
  }
 ]
}