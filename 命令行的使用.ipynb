{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "T5Chem via CLI.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "1_nEy51hGPsb",
    "cellView": "form",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "#@title Select the task type you want to try out, then run this cell\n",
    "\n",
    "task_type = \"product\" #@param [\"product\",\"reactants\",\"reagents\",\"regression\",\"classification\",\"pretrain\",\"mixed\"] {type:\"string\"}\n",
    "has_test = False\n",
    "if task_type == \"mixed\":\n",
    "  print(\"You are selecting 'mixed'! Which means that the model will be trained on a mixed dataset (product, reactants, reagents), and you will need to choose the task type for testing\")\n",
    "elif task_type == \"pretrain\":\n",
    "  print(\"You are selecting 'pretrain'! T5Chem was pretrained in a self-supervised manner and will not have corresponding test task.\")\n",
    "else:\n",
    "  has_test = True\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ### Advanced settings\n",
    "#@markdown Where should the trained model be saved?\n",
    "model_dir = 'model_test/' #@param {type:\"string\"}\n",
    "#@markdown The number of training epochs:\n",
    "num_epoch = 1 #@param {type:\"integer\"}"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3_QfyFKdav8v",
    "outputId": "5a87a52d-fc02-4615-faab-ed5d78b3c70f",
    "cellView": "form",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "#@title Model Training\n",
    "!t5chem train --data_dir data/sample/\"$task_type\"/ --output_dir \"$model_dir\" --task_type \"$task_type\" --pretrain models/pretrain/simple/ --num_epoch \"$num_epoch\""
   ],
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=32, command=<function train at 0x7fcb6be0f950>, data_dir='data/sample/product/', init_lr=0.0005, log_step=5000, num_classes=None, num_epoch=1, output_dir='model_test/', pretrain='models/pretrain/simple/', random_seed=8570, task_type='product', tokenizer='', vocab='')\r\n",
      "***** Running training *****\r\n",
      "  Num examples = 10000\r\n",
      "  Num Epochs = 1\r\n",
      "  Instantaneous batch size per device = 32\r\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\r\n",
      "  Gradient Accumulation steps = 1\r\n",
      "  Total optimization steps = 313\r\n",
      "100%|████████████████████████████████████████▊| 312/313 [00:44<00:00,  6.72it/s]\r\n",
      "\r\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\r\n",
      "\r\n",
      "\r\n",
      "{'train_runtime': 44.6098, 'train_samples_per_second': 224.166, 'train_steps_per_second': 7.016, 'train_loss': 0.2960994342645517, 'epoch': 1.0}\r\n",
      "100%|█████████████████████████████████████████| 313/313 [00:44<00:00,  7.02it/s]\r\n",
      "Namespace(batch_size=32, command=<function train at 0x7fcb6be0f950>, data_dir='data/sample/product/', init_lr=0.0005, log_step=5000, num_classes=None, num_epoch=1, output_dir='model_test/', pretrain='models/pretrain/simple/', random_seed=8570, task_type='product', tokenizer='', vocab='')\r\n",
      "logging dir: model_test/runs/Apr07_11-14-27_wecook\r\n",
      "Saving model checkpoint to model_test/\r\n",
      "Configuration saved in model_test/config.json\r\n",
      "Model weights saved in model_test/pytorch_model.bin\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8Uz7sCkkdf4T",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "#@title Select test task\n",
    "\n",
    "test_type = \"product\" #@param [\"product\",\"reactants\",\"reagents\"] {type:\"string\"}\n",
    "# prefix = ''\n",
    "# In most cases, the model can read prefix from a trained model, but when mixed \n",
    "# training was used (1 model, multiple tasks!), you will need to specifiy prefix\n",
    "# to distinguish between different tasks.\n",
    "task2prefix = {\n",
    "    'product': \"Product:\",\n",
    "    'reactants': \"Reactants:\",\n",
    "    'reagents': \"Reagents:\",\n",
    "}\n",
    "if has_test and task_type != test_type:\n",
    "  print(f\"WARNING, you only trained the model for {task_type}, and only the same task would be available\")\n",
    "  test_type = task_type\n",
    "elif task_type == \"pretrain\":\n",
    "  print(\"Sorry, but there is no test task for pretrain.\")\n",
    "else:\n",
    "  prefix = task2prefix[test_type]\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ### Advanced settings\n",
    "#@markdown Number of batch size for prediction (If the program cannot run \n",
    "#@markdown , try smaller batch size)\n",
    "batch_size =  32#@param {type:\"integer\"}\n",
    "#@markdown The beam size for decoding:\n",
    "beam_size =  5#@param {type:\"integer\"}\n",
    "#@markdown The number of returned sequences:\n",
    "num_seq =  1#@param {type:\"integer\"}\n",
    "\n",
    "if num_seq > beam_size:\n",
    "  raise ValueError(\"num_seq should be <= beam_size!\")\n",
    "\n"
   ],
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wJrKIVHacd5R",
    "outputId": "978ad8d8-c0ef-43f6-bca6-f1a76d7a37cc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "#@title Model Testing\n",
    "# 注意显存，如果不够可能跑不起来\n",
    "!t5chem predict --data_dir data/sample/\"$test_type\"/ --model_dir \"$model_dir\" --batch_size \"$batch_size\" --prefix \"$prefix\" --num_beams \"$beam_size\" --num_preds \"$num_seq\""
   ],
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: 100%|███████████████████████████████| 32/32 [03:06<00:00,  5.83s/it]\r\n",
      "Top-1: 10.4% || Invalid 8.90%\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UGUBLzB3C6WN",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Instructions <a name=\"Instructions\"></a>\n",
    "**Quick start**\n",
    "1. Select a task type in training\n",
    "2. Select a test task type in testing (if you used multi-task training)\n",
    "3. Run all\n",
    "\n",
    "**Trained model**\n",
    "\n",
    "1. Your trained model weights would be avilable in the `model_dir`\n",
    "2. The predictions can be checked under `model_dir`, named `predictions.csv`\n",
    "\n",
    "**Bugs**\n",
    "- If you encounter any bugs, please report the issue to https://github.com/HelloJocelynLu/t5chem/issues\n"
   ]
  }
 ]
}